{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b258997e",
   "metadata": {},
   "source": [
    "\n",
    "# TradingView Strategy Backtest Playground\n",
    "\n",
    "Notebook ini memuat pipeline lengkap untuk menguji sinyal strategi yang diekspor dari TradingView.\n",
    "Ia memandu mulai dari memuat data CSV, mengadaptasikannya ke format QF-Lib, menjalankan backtest,\n",
    "hingga analisis trade kalah dan eksperimen optimasi parameter tambahan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b74196a",
   "metadata": {},
   "source": [
    "\n",
    "> **Struktur notebook**\n",
    ">\n",
    "> 1. Parameter input & pemuatan data\n",
    "> 2. Adaptasi data ke QF-Lib\n",
    "> 3. Strategi berbasis sinyal\n",
    "> 4. Menjalankan backtest & mengekstrak hasil\n",
    "> 5. Visualisasi\n",
    "> 6. Analisis trade kalah & investigasi\n",
    "> 7. Eksplor optimasi parameter\n",
    "> 8. Dokumentasi & reusable structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035dbd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "import itertools\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "from src.qflib_metrics import qflib_metrics_from_returns\n",
    "from src.qflib_adapters import to_qfdataframe, to_qfseries\n",
    "\n",
    "try:\n",
    "    from qf_lib.common.enums.price_field import PriceField\n",
    "    from qf_lib.analysis.timeseries_analysis.timeseries_analysis import TimeseriesAnalysis  # noqa: F401\n",
    "    from qf_lib.containers.dataframe.qf_dataframe import QFDataFrame\n",
    "except ImportError as exc:  # pragma: no cover - dependency guard\n",
    "    raise ImportError(\n",
    "        \"qf-lib harus terinstal. Pastikan `pip install -r requirements.txt` sudah dijalankan.\"\n",
    "    ) from exc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48539c5f",
   "metadata": {},
   "source": [
    "## 1. Parameter input & pemuatan data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441544c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def sanitise_column_name(name: str) -> str:\n",
    "    \"\"\"Konversi nama kolom ke format snake_case yang stabil.\"\"\"\n",
    "    replacements = {\"+\": \" plus \", \"-\": \" minus \", \"@\": \" at \", \"%\": \" pct \"}\n",
    "    for old, new in replacements.items():\n",
    "        name = name.replace(old, new)\n",
    "    name = re.sub(r\"[^0-9a-zA-Z]+\", \"_\", name)\n",
    "    name = re.sub(r\"_+\", \"_\", name)\n",
    "    return name.strip(\"_\").lower()\n",
    "\n",
    "\n",
    "def sanitise_columns(columns: Iterable[str]) -> Tuple[List[str], Dict[str, str]]:\n",
    "    \"\"\"Berikan daftar nama kolom unik serta mapping sanitised -> original.\"\"\"\n",
    "    seen: Dict[str, int] = {}\n",
    "    sanitised: List[str] = []\n",
    "    mapping: Dict[str, str] = {}\n",
    "\n",
    "    for original in columns:\n",
    "        base = sanitise_column_name(original)\n",
    "        count = seen.get(base, 0)\n",
    "        if count > 0:\n",
    "            candidate = f\"{base}_{count + 1}\"\n",
    "        else:\n",
    "            candidate = base\n",
    "        seen[base] = count + 1\n",
    "        sanitised.append(candidate)\n",
    "        mapping[candidate] = original\n",
    "\n",
    "    return sanitised, mapping\n",
    "\n",
    "\n",
    "def load_strategy_csv(\n",
    "    path: Path,\n",
    "    time_column: str,\n",
    "    tz_localize: Optional[str] = None,\n",
    "    tz_convert: Optional[str] = None,\n",
    ") -> Tuple[pd.DataFrame, Dict[str, str]]:\n",
    "    \"\"\"Muat CSV strategi TradingView dan kembalikan DataFrame bernomor float dengan index datetime.\"\"\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File tidak ditemukan: {path}\")\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if time_column not in df.columns:\n",
    "        raise KeyError(f\"Kolom waktu '{time_column}' tidak ada di file {path.name}\")\n",
    "\n",
    "    time_values = df.pop(time_column)\n",
    "    if np.issubdtype(time_values.dtype, np.number):\n",
    "        index = pd.to_datetime(time_values, unit=\"s\", utc=True)\n",
    "    else:\n",
    "        index = pd.to_datetime(time_values, utc=True, infer_datetime_format=True)\n",
    "\n",
    "    if tz_localize is not None:\n",
    "        index = index.tz_localize(tz_localize)\n",
    "    if tz_convert is not None:\n",
    "        index = index.tz_convert(tz_convert)\n",
    "\n",
    "    index = index.tz_convert(None)\n",
    "\n",
    "    sanitised_names, mapping = sanitise_columns(df.columns)\n",
    "    df.columns = sanitised_names\n",
    "    df.index = index\n",
    "    df = df.sort_index()\n",
    "\n",
    "    numeric_df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "    return numeric_df, mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ed81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_FILE = \"OKX_BTCUSDT, 1D.csv\"\n",
    "TIME_COLUMN = \"time\"\n",
    "PRICE_COLUMN = \"close\"\n",
    "ASSUME_SAME_BAR_EXECUTION = True\n",
    "\n",
    "signal_columns = {\n",
    "    \"long_entry\": sanitise_column_name(\"Reversal Up +\"),\n",
    "    \"long_exit\": sanitise_column_name(\"Reversal Down -\"),\n",
    "    \"short_entry\": sanitise_column_name(\"Reversal Down +\"),\n",
    "    \"short_exit\": sanitise_column_name(\"Reversal Up -\"),\n",
    "}\n",
    "\n",
    "filters_template = {\n",
    "    \"min_money_flow_long\": None,\n",
    "    \"max_money_flow_short\": None,\n",
    "    \"min_confluence_value\": None,\n",
    "    \"require_ema_trend_confirmation\": False,\n",
    "}\n",
    "\n",
    "context_feature_candidates = [\n",
    "    \"ema\",\n",
    "    \"money_flow\",\n",
    "    \"confluence_meter_value\",\n",
    "    \"atr\",\n",
    "    \"macd\",\n",
    "    \"signal\",\n",
    "    \"histogram\",\n",
    "]\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / DATA_FILE\n",
    "raw_df, column_lookup = load_strategy_csv(DATA_PATH, TIME_COLUMN)\n",
    "\n",
    "available_context_columns = [col for col in context_feature_candidates if col in raw_df.columns]\n",
    "\n",
    "print(f\"Total bar data: {len(raw_df):,}\")\n",
    "print(f\"Rentang tanggal: {raw_df.index.min()} â†’ {raw_df.index.max()}\")\n",
    "print(f\"Kolom harga utama tersedia: {[c for c in ['open','high','low','close'] if c in raw_df.columns]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70da5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "column_overview = (\n",
    "    pd.DataFrame(\n",
    "        {\n",
    "            \"sanitised\": list(column_lookup.keys()),\n",
    "            \"original\": list(column_lookup.values()),\n",
    "        }\n",
    "    )\n",
    "    .sort_values(\"sanitised\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "column_overview.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa5d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if PRICE_COLUMN not in raw_df.columns:\n",
    "    raise KeyError(f\"Kolom harga '{PRICE_COLUMN}' tidak ditemukan dalam data yang disanitasi\")\n",
    "\n",
    "missing_signals = [alias for alias in signal_columns.values() if alias not in raw_df.columns]\n",
    "if missing_signals:\n",
    "    raise KeyError(\n",
    "        \"Kolom sinyal berikut tidak ditemukan. Periksa parameter `signal_columns`: \"\n",
    "        + \", \".join(missing_signals)\n",
    "    )\n",
    "\n",
    "signals_preview = raw_df[list(dict.fromkeys(signal_columns.values()))].copy()\n",
    "signals_preview.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2367ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = raw_df.copy()\n",
    "\n",
    "df[\"ema_slope\"] = df[\"ema\"].diff() if \"ema\" in df.columns else np.nan\n",
    "if \"money_flow\" in df.columns:\n",
    "    df[\"money_flow_z\"] = pd.qcut(df[\"money_flow\"], q=5, duplicates=\"drop\")\n",
    "if \"confluence_meter_value\" in df.columns:\n",
    "    df[\"confluence_meter_rank\"] = pd.qcut(df[\"confluence_meter_value\"], q=5, duplicates=\"drop\")\n",
    "\n",
    "context_columns = [*available_context_columns]\n",
    "if \"ema_slope\" in df.columns:\n",
    "    context_columns.append(\"ema_slope\")\n",
    "\n",
    "print(f\"Context features yang digunakan pada log trade: {context_columns}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d083217a",
   "metadata": {},
   "source": [
    "## 2. Adaptasi data ke QF-Lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "price_fields = {\n",
    "    PriceField.Open: df[\"open\"] if \"open\" in df.columns else pd.Series(np.nan, index=df.index),\n",
    "    PriceField.High: df[\"high\"] if \"high\" in df.columns else pd.Series(np.nan, index=df.index),\n",
    "    PriceField.Low: df[\"low\"] if \"low\" in df.columns else pd.Series(np.nan, index=df.index),\n",
    "    PriceField.Close: df[PRICE_COLUMN],\n",
    "}\n",
    "\n",
    "price_qf = QFDataFrame(pd.DataFrame(price_fields))\n",
    "signal_qf = to_qfdataframe(df[list(dict.fromkeys(signal_columns.values()))])\n",
    "\n",
    "price_qf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfba03ba",
   "metadata": {},
   "source": [
    "## 3. Strategi berbasis sinyal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class TradeRecord:\n",
    "    trade_id: int\n",
    "    direction: str\n",
    "    entry_time: pd.Timestamp\n",
    "    exit_time: pd.Timestamp\n",
    "    entry_price: float\n",
    "    exit_price: float\n",
    "    pnl_pct: float\n",
    "    pnl_currency: float\n",
    "    bars_held: int\n",
    "    exit_reason: str\n",
    "    entry_context: Dict[str, float] = field(default_factory=dict)\n",
    "    exit_context: Dict[str, float] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "class ExcelSignalStrategy:\n",
    "    \"\"\"Bangun posisi berdasarkan sinyal yang sudah dihitung di CSV TradingView.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        price_column: str,\n",
    "        signal_columns: Dict[str, str],\n",
    "        filters: Dict[str, Optional[float]],\n",
    "        context_columns: Optional[List[str]] = None,\n",
    "        assume_same_bar_execution: bool = True,\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.price_column = price_column\n",
    "        self.signal_columns = signal_columns\n",
    "        self.filters = filters\n",
    "        self.context_columns = context_columns or []\n",
    "        self.assume_same_bar_execution = assume_same_bar_execution\n",
    "\n",
    "        missing = [col for col in signal_columns.values() if col not in data.columns]\n",
    "        if missing:\n",
    "            raise KeyError(f\"Kolom sinyal tidak ditemukan dalam data: {missing}\")\n",
    "\n",
    "        if price_column not in data.columns:\n",
    "            raise KeyError(f\"Kolom harga '{price_column}' tidak tersedia\")\n",
    "\n",
    "        self._signal_frame = {\n",
    "            name: self._to_boolean_series(self.data[column])\n",
    "            for name, column in self.signal_columns.items()\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _to_boolean_series(series: pd.Series) -> pd.Series:\n",
    "        if series.dtype == bool:\n",
    "            return series.fillna(False)\n",
    "        numeric = pd.to_numeric(series, errors=\"coerce\")\n",
    "        if numeric.notna().any():\n",
    "            return numeric.fillna(0.0).astype(float).abs() > 0.0\n",
    "        return series.astype(str).str.strip().ne(\"\")\n",
    "\n",
    "    def _extract_context(self, row: pd.Series) -> Dict[str, float]:\n",
    "        context = {}\n",
    "        for col in self.context_columns:\n",
    "            context[col] = float(row.get(col, np.nan)) if pd.notna(row.get(col, np.nan)) else np.nan\n",
    "        return context\n",
    "\n",
    "    def _passes_long_filters(self, row: pd.Series) -> bool:\n",
    "        if self.filters.get(\"min_money_flow_long\") is not None and \"money_flow\" in row.index:\n",
    "            if row[\"money_flow\"] < float(self.filters[\"min_money_flow_long\"]):\n",
    "                return False\n",
    "        if self.filters.get(\"min_confluence_value\") is not None and \"confluence_meter_value\" in row.index:\n",
    "            if row[\"confluence_meter_value\"] < float(self.filters[\"min_confluence_value\"]):\n",
    "                return False\n",
    "        if self.filters.get(\"require_ema_trend_confirmation\") and \"ema_slope\" in row.index:\n",
    "            if row[\"ema_slope\"] < 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def _passes_short_filters(self, row: pd.Series) -> bool:\n",
    "        if self.filters.get(\"max_money_flow_short\") is not None and \"money_flow\" in row.index:\n",
    "            if row[\"money_flow\"] > float(self.filters[\"max_money_flow_short\"]):\n",
    "                return False\n",
    "        if self.filters.get(\"min_confluence_value\") is not None and \"confluence_meter_value\" in row.index:\n",
    "            if row[\"confluence_meter_value\"] < float(self.filters[\"min_confluence_value\"]):\n",
    "                return False\n",
    "        if self.filters.get(\"require_ema_trend_confirmation\") and \"ema_slope\" in row.index:\n",
    "            if row[\"ema_slope\"] > 0:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def run(self) -> Tuple[pd.Series, pd.DataFrame]:\n",
    "        index = self.data.index\n",
    "        position_values = np.zeros(len(index), dtype=float)\n",
    "        trades: List[TradeRecord] = []\n",
    "\n",
    "        current_pos = 0\n",
    "        entry_idx: Optional[int] = None\n",
    "        entry_price: Optional[float] = None\n",
    "        entry_row: Optional[pd.Series] = None\n",
    "        entry_direction: Optional[str] = None\n",
    "\n",
    "        long_entry_series = self._signal_frame.get(\"long_entry\")\n",
    "        long_exit_series = self._signal_frame.get(\"long_exit\")\n",
    "        short_entry_series = self._signal_frame.get(\"short_entry\")\n",
    "        short_exit_series = self._signal_frame.get(\"short_exit\")\n",
    "\n",
    "        for i, (timestamp, row) in enumerate(self.data.iterrows()):\n",
    "            price = float(row[self.price_column])\n",
    "            long_entry = bool(long_entry_series.iloc[i]) if long_entry_series is not None else False\n",
    "            long_exit = bool(long_exit_series.iloc[i]) if long_exit_series is not None else False\n",
    "            short_entry = bool(short_entry_series.iloc[i]) if short_entry_series is not None else False\n",
    "            short_exit = bool(short_exit_series.iloc[i]) if short_exit_series is not None else False\n",
    "\n",
    "            exit_trade = False\n",
    "            exit_reason = \"\"\n",
    "\n",
    "            if current_pos > 0:\n",
    "                if long_exit:\n",
    "                    exit_trade = True\n",
    "                    exit_reason = \"long_exit_signal\"\n",
    "                elif short_entry:\n",
    "                    exit_trade = True\n",
    "                    exit_reason = \"short_reversal\"\n",
    "            elif current_pos < 0:\n",
    "                if short_exit:\n",
    "                    exit_trade = True\n",
    "                    exit_reason = \"short_exit_signal\"\n",
    "                elif long_entry:\n",
    "                    exit_trade = True\n",
    "                    exit_reason = \"long_reversal\"\n",
    "\n",
    "            if exit_trade and entry_idx is not None and entry_price is not None and entry_direction is not None:\n",
    "                pnl_pct = (price / entry_price - 1.0)\n",
    "                if entry_direction == \"Short\":\n",
    "                    pnl_pct = -pnl_pct\n",
    "                pnl_currency = pnl_pct * entry_price\n",
    "                bars_held = i - entry_idx\n",
    "                trade = TradeRecord(\n",
    "                    trade_id=len(trades) + 1,\n",
    "                    direction=entry_direction,\n",
    "                    entry_time=index[entry_idx],\n",
    "                    exit_time=timestamp,\n",
    "                    entry_price=entry_price,\n",
    "                    exit_price=price,\n",
    "                    pnl_pct=pnl_pct,\n",
    "                    pnl_currency=pnl_currency,\n",
    "                    bars_held=bars_held,\n",
    "                    exit_reason=exit_reason,\n",
    "                    entry_context=self._extract_context(entry_row) if entry_row is not None else {},\n",
    "                    exit_context=self._extract_context(row),\n",
    "                )\n",
    "                trades.append(trade)\n",
    "                current_pos = 0\n",
    "                entry_idx = None\n",
    "                entry_price = None\n",
    "                entry_row = None\n",
    "                entry_direction = None\n",
    "\n",
    "            if current_pos == 0:\n",
    "                if long_entry and self._passes_long_filters(row):\n",
    "                    current_pos = 1\n",
    "                    entry_idx = i\n",
    "                    entry_price = price\n",
    "                    entry_row = row\n",
    "                    entry_direction = \"Long\"\n",
    "                elif short_entry and self._passes_short_filters(row):\n",
    "                    current_pos = -1\n",
    "                    entry_idx = i\n",
    "                    entry_price = price\n",
    "                    entry_row = row\n",
    "                    entry_direction = \"Short\"\n",
    "\n",
    "            position_values[i] = current_pos\n",
    "\n",
    "        if current_pos != 0 and entry_idx is not None and entry_price is not None and entry_direction is not None:\n",
    "            timestamp = index[-1]\n",
    "            price = float(self.data.iloc[-1][self.price_column])\n",
    "            pnl_pct = (price / entry_price - 1.0)\n",
    "            if entry_direction == \"Short\":\n",
    "                pnl_pct = -pnl_pct\n",
    "            pnl_currency = pnl_pct * entry_price\n",
    "            bars_held = len(index) - entry_idx - 1\n",
    "            trade = TradeRecord(\n",
    "                trade_id=len(trades) + 1,\n",
    "                direction=entry_direction,\n",
    "                entry_time=index[entry_idx],\n",
    "                exit_time=timestamp,\n",
    "                entry_price=entry_price,\n",
    "                exit_price=price,\n",
    "                pnl_pct=pnl_pct,\n",
    "                pnl_currency=pnl_currency,\n",
    "                bars_held=bars_held,\n",
    "                exit_reason=\"forced_exit_at_end\",\n",
    "                entry_context=self._extract_context(entry_row) if entry_row is not None else {},\n",
    "                exit_context=self._extract_context(self.data.iloc[-1]),\n",
    "            )\n",
    "            trades.append(trade)\n",
    "\n",
    "        positions = pd.Series(position_values, index=index, name=\"position\")\n",
    "\n",
    "        trade_records = []\n",
    "        for trade in trades:\n",
    "            record = {\n",
    "                \"trade_id\": trade.trade_id,\n",
    "                \"direction\": trade.direction,\n",
    "                \"entry_time\": trade.entry_time,\n",
    "                \"exit_time\": trade.exit_time,\n",
    "                \"entry_price\": trade.entry_price,\n",
    "                \"exit_price\": trade.exit_price,\n",
    "                \"pnl_pct\": trade.pnl_pct,\n",
    "                \"pnl_currency\": trade.pnl_currency,\n",
    "                \"bars_held\": trade.bars_held,\n",
    "                \"exit_reason\": trade.exit_reason,\n",
    "            }\n",
    "            for key, value in (trade.entry_context or {}).items():\n",
    "                record[f\"entry_{key}\"] = value\n",
    "            for key, value in (trade.exit_context or {}).items():\n",
    "                record[f\"exit_{key}\"] = value\n",
    "            trade_records.append(record)\n",
    "\n",
    "        trades_df = pd.DataFrame(trade_records)\n",
    "        if not trades_df.empty:\n",
    "            trades_df = trades_df.sort_values(\"entry_time\").reset_index(drop=True)\n",
    "\n",
    "        return positions, trades_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c095321b",
   "metadata": {},
   "source": [
    "## 4. Menjalankan backtest & mengekstrak hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f19c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_backtest_pipeline(\n",
    "    data: pd.DataFrame,\n",
    "    price_column: str,\n",
    "    signal_columns: Dict[str, str],\n",
    "    filters: Dict[str, Optional[float]],\n",
    "    context_columns: Optional[List[str]] = None,\n",
    "    assume_same_bar_execution: bool = True,\n",
    ") -> Dict[str, object]:\n",
    "    strategy = ExcelSignalStrategy(\n",
    "        data=data,\n",
    "        price_column=price_column,\n",
    "        signal_columns=signal_columns,\n",
    "        filters=filters,\n",
    "        context_columns=context_columns,\n",
    "        assume_same_bar_execution=assume_same_bar_execution,\n",
    "    )\n",
    "\n",
    "    positions, trades_df = strategy.run()\n",
    "\n",
    "    asset_returns = data[price_column].pct_change().fillna(0.0)\n",
    "    strategy_returns = positions.shift(1).fillna(0.0) * asset_returns\n",
    "    equity_curve = (1.0 + strategy_returns).cumprod()\n",
    "\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"close\": data[price_column],\n",
    "            \"asset_return\": asset_returns,\n",
    "            \"position\": positions,\n",
    "            \"strategy_return\": strategy_returns,\n",
    "            \"equity_curve\": equity_curve,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    rolling_max = results_df[\"equity_curve\"].cummax()\n",
    "    results_df[\"drawdown\"] = results_df[\"equity_curve\"] / rolling_max - 1.0\n",
    "\n",
    "    metrics = qflib_metrics_from_returns(strategy_returns)\n",
    "\n",
    "    trade_summary = {\n",
    "        \"total_trades\": int(len(trades_df)),\n",
    "        \"long_trades\": int((trades_df[\"direction\"] == \"Long\").sum()) if not trades_df.empty else 0,\n",
    "        \"short_trades\": int((trades_df[\"direction\"] == \"Short\").sum()) if not trades_df.empty else 0,\n",
    "        \"win_rate\": float((trades_df[\"pnl_pct\"] > 0).mean()) if not trades_df.empty else np.nan,\n",
    "        \"avg_pnl_pct\": float(trades_df[\"pnl_pct\"].mean()) if not trades_df.empty else np.nan,\n",
    "        \"median_bars\": float(trades_df[\"bars_held\"].median()) if not trades_df.empty else np.nan,\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        \"positions\": positions,\n",
    "        \"trades\": trades_df,\n",
    "        \"results\": results_df,\n",
    "        \"metrics\": metrics,\n",
    "        \"trade_summary\": trade_summary,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bbd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "base_filters = filters_template.copy()\n",
    "backtest_outputs = run_backtest_pipeline(\n",
    "    data=df,\n",
    "    price_column=PRICE_COLUMN,\n",
    "    signal_columns=signal_columns,\n",
    "    filters=base_filters,\n",
    "    context_columns=context_columns,\n",
    "    assume_same_bar_execution=ASSUME_SAME_BAR_EXECUTION,\n",
    ")\n",
    "\n",
    "metrics_series = pd.Series(backtest_outputs[\"metrics\"])\n",
    "summary_series = pd.Series(backtest_outputs[\"trade_summary\"])\n",
    "\n",
    "print(\"=== QF-Lib Metrics ===\")\n",
    "display(metrics_series.to_frame(\"value\"))\n",
    "\n",
    "print(\"=== Ringkasan Trade ===\")\n",
    "display(summary_series.to_frame(\"value\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771ebd5e",
   "metadata": {},
   "source": [
    "## 5. Visualisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_df = backtest_outputs[\"results\"]\n",
    "trades_df = backtest_outputs[\"trades\"]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 18), sharex=True)\n",
    "\n",
    "axes[0].plot(results_df.index, results_df[\"close\"], label=\"Close\", color=\"#1f77b4\")\n",
    "if not trades_df.empty:\n",
    "    long_trades = trades_df[trades_df[\"direction\"] == \"Long\"]\n",
    "    short_trades = trades_df[trades_df[\"direction\"] == \"Short\"]\n",
    "    axes[0].scatter(long_trades[\"entry_time\"], long_trades[\"entry_price\"], marker=\"^\", color=\"#2ca02c\", s=80, label=\"Long Entry\")\n",
    "    axes[0].scatter(long_trades[\"exit_time\"], long_trades[\"exit_price\"], marker=\"v\", color=\"#98df8a\", s=80, label=\"Long Exit\")\n",
    "    axes[0].scatter(short_trades[\"entry_time\"], short_trades[\"entry_price\"], marker=\"v\", color=\"#d62728\", s=80, label=\"Short Entry\")\n",
    "    axes[0].scatter(short_trades[\"exit_time\"], short_trades[\"exit_price\"], marker=\"^\", color=\"#ff9896\", s=80, label=\"Short Exit\")\n",
    "axes[0].set_title(\"Harga & Sinyal Entry/Exit\")\n",
    "axes[0].set_ylabel(\"Harga\")\n",
    "axes[0].legend(loc=\"upper left\")\n",
    "\n",
    "axes[1].plot(results_df.index, results_df[\"equity_curve\"], color=\"#ff7f0e\", label=\"Equity Curve\")\n",
    "axes[1].fill_between(results_df.index, results_df[\"equity_curve\"], results_df[\"equity_curve\"].cummax(), color=\"#ffbb78\", alpha=0.3)\n",
    "axes[1].set_title(\"Equity Curve & Drawdown\")\n",
    "axes[1].set_ylabel(\"Equity\")\n",
    "axes[1].legend(loc=\"upper left\")\n",
    "\n",
    "axes[2].plot(results_df.index, results_df[\"position\"], color=\"#9467bd\")\n",
    "axes[2].set_title(\"Posisi (1=Long, -1=Short, 0=Flat)\")\n",
    "axes[2].set_ylabel(\"Posisi\")\n",
    "axes[2].set_xlabel(\"Tanggal\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if not trades_df.empty:\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax[0].hist(trades_df[\"pnl_pct\"] * 100.0, bins=20, color=\"#1f77b4\", alpha=0.8)\n",
    "    ax[0].set_title(\"Distribusi PnL per Trade (%)\")\n",
    "    ax[0].set_xlabel(\"PnL (%)\")\n",
    "    ax[0].set_ylabel(\"Jumlah Trade\")\n",
    "\n",
    "    ax[1].scatter(trades_df[\"bars_held\"], trades_df[\"pnl_pct\"] * 100.0, color=\"#ff7f0e\", alpha=0.7)\n",
    "    ax[1].set_title(\"Durasi vs PnL\")\n",
    "    ax[1].set_xlabel(\"Bars Held\")\n",
    "    ax[1].set_ylabel(\"PnL (%)\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24192ba9",
   "metadata": {},
   "source": [
    "## 6. Analisis trade kalah & investigasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09b1d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trades_df = backtest_outputs[\"trades\"]\n",
    "\n",
    "if trades_df.empty:\n",
    "    print(\"Tidak ada trade untuk dianalisis.\")\n",
    "else:\n",
    "    losing_trades = trades_df[trades_df[\"pnl_pct\"] < 0].copy()\n",
    "    print(f\"Total losing trades: {len(losing_trades)} dari {len(trades_df)} total trade\")\n",
    "\n",
    "    if not losing_trades.empty:\n",
    "        if \"entry_ema_slope\" in losing_trades.columns:\n",
    "            losing_trades[\"ema_trend_state\"] = np.where(\n",
    "                losing_trades[\"entry_ema_slope\"] >= 0, \"EMA Rising\", \"EMA Falling\"\n",
    "            )\n",
    "        if \"entry_money_flow\" in losing_trades.columns:\n",
    "            losing_trades[\"money_flow_bucket\"] = pd.cut(\n",
    "                losing_trades[\"entry_money_flow\"],\n",
    "                bins=[-math.inf, 40, 60, math.inf],\n",
    "                labels=[\"<40\", \"40-60\", \">60\"],\n",
    "            )\n",
    "        if \"entry_confluence_meter_value\" in losing_trades.columns:\n",
    "            losing_trades[\"confluence_bucket\"] = pd.cut(\n",
    "                losing_trades[\"entry_confluence_meter_value\"],\n",
    "                bins=[-math.inf, 40, 60, 80, math.inf],\n",
    "                labels=[\"<40\", \"40-60\", \"60-80\", \">80\"],\n",
    "            )\n",
    "\n",
    "        grouping_columns = [\n",
    "            col\n",
    "            for col in [\"direction\", \"ema_trend_state\", \"money_flow_bucket\", \"confluence_bucket\"]\n",
    "            if col in losing_trades.columns\n",
    "        ]\n",
    "        if grouping_columns:\n",
    "            classification = (\n",
    "                losing_trades.groupby(grouping_columns)\n",
    "                .agg(\n",
    "                    count=(\"trade_id\", \"count\"),\n",
    "                    avg_loss_pct=(\"pnl_pct\", lambda x: float(x.mean() * 100.0)),\n",
    "                    median_bars=(\"bars_held\", \"median\"),\n",
    "                )\n",
    "                .sort_values(\"count\", ascending=False)\n",
    "            )\n",
    "            display(classification)\n",
    "        else:\n",
    "            print(\"Kolom konteks tidak cukup untuk klasifikasi detail.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8ad782",
   "metadata": {},
   "source": [
    "## 7. Eksplor optimasi parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dc4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimization_candidates = []\n",
    "money_flow_thresholds = [None, 50, 55, 60]\n",
    "confluence_thresholds = [None, 55, 65, 75]\n",
    "ema_confirmation_options = [False, True]\n",
    "\n",
    "for money_flow, confluence, ema_confirm in itertools.product(\n",
    "    money_flow_thresholds, confluence_thresholds, ema_confirmation_options\n",
    "):\n",
    "    candidate_filters = filters_template.copy()\n",
    "    candidate_filters[\"min_money_flow_long\"] = money_flow\n",
    "    candidate_filters[\"max_money_flow_short\"] = money_flow\n",
    "    candidate_filters[\"min_confluence_value\"] = confluence\n",
    "    candidate_filters[\"require_ema_trend_confirmation\"] = ema_confirm\n",
    "\n",
    "    outputs = run_backtest_pipeline(\n",
    "        data=df,\n",
    "        price_column=PRICE_COLUMN,\n",
    "        signal_columns=signal_columns,\n",
    "        filters=candidate_filters,\n",
    "        context_columns=context_columns,\n",
    "        assume_same_bar_execution=ASSUME_SAME_BAR_EXECUTION,\n",
    "    )\n",
    "\n",
    "    metrics = outputs[\"metrics\"]\n",
    "    trade_summary = outputs[\"trade_summary\"]\n",
    "\n",
    "    optimization_candidates.append(\n",
    "        {\n",
    "            \"min_money_flow\": money_flow,\n",
    "            \"min_confluence\": confluence,\n",
    "            \"ema_confirm\": ema_confirm,\n",
    "            \"cagr\": metrics.get(\"cagr\", np.nan),\n",
    "            \"sharpe\": metrics.get(\"sharpe_ratio\", np.nan),\n",
    "            \"max_drawdown\": metrics.get(\"max_drawdown\", np.nan),\n",
    "            \"total_trades\": trade_summary.get(\"total_trades\", 0),\n",
    "            \"win_rate\": trade_summary.get(\"win_rate\", np.nan),\n",
    "        }\n",
    "    )\n",
    "\n",
    "optimization_df = pd.DataFrame(optimization_candidates)\n",
    "optimization_df = optimization_df.sort_values([\"cagr\", \"sharpe\"], ascending=[False, False]).reset_index(drop=True)\n",
    "optimization_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca250088",
   "metadata": {},
   "source": [
    "## 8. Dokumentasi & reusable structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50b3a1",
   "metadata": {},
   "source": [
    "\n",
    "### Cara menggunakan notebook ini\n",
    "\n",
    "1. **Set parameter input** pada sel konfigurasi (nama file, kolom sinyal, filter).\n",
    "2. **Jalankan blok pemuatan data** untuk memastikan kolom yang dipakai sudah benar.\n",
    "3. **Tinjau adaptasi QF-Lib** guna memverifikasi harga dan sinyal siap dipakai.\n",
    "4. **Jalankan backtest** dan telaah tabel metrik + ringkasan trade.\n",
    "5. **Gunakan visualisasi** untuk memahami waktu entry/exit serta kinerja ekuitas.\n",
    "6. **Pelajari trade yang kalah** lewat tabel klasifikasi untuk menemukan pola kelemahan.\n",
    "7. **Eksplorasi optimasi** dengan memodifikasi grid filter atau menambahkan kondisi baru.\n",
    "8. **Salin fungsi utilitas** (`load_strategy_csv`, `ExcelSignalStrategy`, `run_backtest_pipeline`) ke modul terpisah\n",
    "   bila ingin dijadikan library reuse di luar notebook.\n",
    "\n",
    "Notebook ini dirancang agar cukup dengan mengganti `DATA_FILE` dan `signal_columns`, Anda dapat langsung\n",
    "menguji file strategi TradingView lainnya tanpa memodifikasi kode inti.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
