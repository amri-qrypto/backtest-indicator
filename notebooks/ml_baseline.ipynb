{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439a5757",
   "metadata": {},
   "source": [
    "# ML Baseline Models\n",
    "Notebook ini membangun baseline machine learning berbasis fitur OHLCV harian ETHUSDT.\n",
    "Dataset processed akan disimpan ulang agar dapat dipakai ulang oleh pipeline berikutnya,\n",
    "kemudian model linear (Lasso/ElasticNet) serta LightGBM dievaluasi menggunakan skema TimeSeriesSplit\n",
    "dan window out-of-sample tahun 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d41609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    roc_auc_score,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "import lightgbm as lgb\n",
    "import joblib\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def locate_project_root() -> Path:\n",
    "    \"\"\"Cari folder proyek yang menyimpan data dan notebook.\"\"\"\n",
    "    current = Path.cwd().resolve()\n",
    "    for candidate in (current, *current.parents):\n",
    "        if (candidate / 'data').exists() and (candidate / 'notebooks').exists():\n",
    "            return candidate\n",
    "    return current\n",
    "\n",
    "\n",
    "PROJECT_ROOT = locate_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'BINANCE_ETHUSDT.P, 60.csv'\n",
    "PROCESSED_PATH = PROJECT_ROOT / 'data' / 'processed' / 'ethusdt_hourly_features.csv'\n",
    "MODEL_DIR = PROJECT_ROOT / 'outputs' / 'models'\n",
    "PREDICTION_DIR = PROJECT_ROOT / 'outputs' / 'predictions'\n",
    "\n",
    "from src.performance.metrics import DEFAULT_BARS_PER_YEAR, summarise_fold_performance\n",
    "\n",
    "BARS_PER_DAY = 24.0\n",
    "BARS_PER_YEAR = float(BARS_PER_DAY * 365.0)\n",
    "HORIZON_HOURS = 5\n",
    "RETURN_TYPE = 'simple'\n",
    "WALKFORWARD_SPLITS = 5\n",
    "\n",
    "PROCESSED_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "PREDICTION_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def root_mean_squared_error(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "    \"\"\"Hitung RMSE yang kompatibel dengan berbagai versi scikit-learn.\"\"\"\n",
    "    try:\n",
    "        return float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        return float(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17e9a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset memiliki 25383 baris dengan 11 fitur.\n",
      "Dataset tersimpan ke C:\\Users\\jefri\\backtest-indicator\\data\\processed\\ethusdt_hourly_features.csv\n"
     ]
    }
   ],
   "source": [
    "def load_ohlcv(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Load OHLCV CSV dan bersihkan kolomnya.\"\"\"\n",
    "\n",
    "    path = Path(path).expanduser()\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"Dataset {path} tidak tersedia. Download data terlebih dahulu atau ubah DATA_PATH.\"\n",
    "        )\n",
    "\n",
    "    raw = pd.read_csv(path)\n",
    "    raw.columns = [col.strip().lower().replace(' ', '_') for col in raw.columns]\n",
    "    keep = ['time', 'open', 'high', 'low', 'close', 'volume']\n",
    "    missing = [col for col in keep if col not in raw.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Missing columns {missing} in {path}\")\n",
    "    ohlcv = raw[keep].copy()\n",
    "    ohlcv['time'] = pd.to_datetime(ohlcv['time'], utc=True)\n",
    "    numeric_cols = [col for col in keep if col != 'time']\n",
    "    ohlcv[numeric_cols] = ohlcv[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    ohlcv = ohlcv.dropna().set_index('time').sort_index()\n",
    "    return ohlcv\n",
    "\n",
    "\n",
    "def engineer_features(ohlcv: pd.DataFrame) -> pd.DataFrame:\n",
    "    close = ohlcv['close'].astype(float)\n",
    "    volume = ohlcv['volume'].astype(float)\n",
    "    features = pd.DataFrame(index=ohlcv.index)\n",
    "    features['ret_1d'] = close.pct_change(1)\n",
    "    features['ret_5d'] = close.pct_change(5)\n",
    "    features['ret_20d'] = close.pct_change(20)\n",
    "    features['momentum_20d'] = features['ret_1d'].rolling(20).mean()\n",
    "    features['momentum_60d'] = features['ret_1d'].rolling(60).mean()\n",
    "    features['volatility_20d'] = features['ret_1d'].rolling(20).std()\n",
    "    features['volatility_60d'] = features['ret_1d'].rolling(60).std()\n",
    "    features['volume_change'] = volume.pct_change(1)\n",
    "    features['volume_zscore_20d'] = (volume - volume.rolling(20).mean()) / volume.rolling(20).std()\n",
    "    ema_fast = close.ewm(span=20, adjust=False).mean()\n",
    "    ema_slow = close.ewm(span=60, adjust=False).mean()\n",
    "    features['price_ema_spread'] = (ema_fast - ema_slow) / ema_slow\n",
    "    features['high_low_range'] = (ohlcv['high'] - ohlcv['low']) / close\n",
    "    return features\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    ohlcv: pd.DataFrame,\n",
    "    horizon: int = HORIZON_HOURS,\n",
    "    return_type: str = RETURN_TYPE,\n",
    ") -> pd.DataFrame:\n",
    "    features = engineer_features(ohlcv)\n",
    "    if return_type == 'log':\n",
    "        forward_returns = (np.log(ohlcv['close'].shift(-horizon)) - np.log(ohlcv['close']))\n",
    "    elif return_type == 'simple':\n",
    "        forward_returns = ohlcv['close'].pct_change(horizon).shift(-horizon)\n",
    "    else:\n",
    "        raise ValueError(\"return_type harus 'simple' atau 'log'.\")\n",
    "    labels = (forward_returns > 0).astype(int).rename('target')\n",
    "    dataset = features.join(labels).join(forward_returns.rename('future_return'))\n",
    "    dataset = dataset.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    return dataset\n",
    "\n",
    "\n",
    "ohlcv = load_ohlcv(DATA_PATH)\n",
    "dataset = build_dataset(ohlcv, horizon=HORIZON_HOURS, return_type=RETURN_TYPE)\n",
    "print(f\"Dataset memiliki {len(dataset)} baris dengan {dataset.shape[1]-2} fitur.\")\n",
    "dataset.to_csv(PROCESSED_PATH)\n",
    "print(f\"Dataset tersimpan ke {PROCESSED_PATH}\")\n",
    "\n",
    "dataset_metadata = pd.DataFrame(\n",
    "    [\n",
    "        (\"horizon_hours\", HORIZON_HOURS),\n",
    "        (\"return_type\", RETURN_TYPE),\n",
    "        (\"target_definition\", \"1 jika forward_return > 0 else 0\"),\n",
    "        (\"rows\", len(dataset)),\n",
    "        (\"start_time\", dataset.index.min()),\n",
    "        (\"end_time\", dataset.index.max()),\n",
    "    ],\n",
    "    columns=[\"key\", \"value\"],\n",
    ").set_index(\"key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c6f6895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performa walk-forward (train folds):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>n_bars</th>\n",
       "      <th>mean_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>annualised_vol</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>hit_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-03 12:00:00+00:00</td>\n",
       "      <td>2023-06-28 20:00:00+00:00</td>\n",
       "      <td>4233.0</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.012423</td>\n",
       "      <td>1.162749</td>\n",
       "      <td>4.248437</td>\n",
       "      <td>0.504370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03 12:00:00+00:00</td>\n",
       "      <td>2023-12-22 02:00:00+00:00</td>\n",
       "      <td>8463.0</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.010998</td>\n",
       "      <td>1.029359</td>\n",
       "      <td>3.654064</td>\n",
       "      <td>0.505731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-03 12:00:00+00:00</td>\n",
       "      <td>2024-06-15 08:00:00+00:00</td>\n",
       "      <td>12693.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.012484</td>\n",
       "      <td>1.168447</td>\n",
       "      <td>3.754545</td>\n",
       "      <td>0.509415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-03 12:00:00+00:00</td>\n",
       "      <td>2024-12-08 14:00:00+00:00</td>\n",
       "      <td>16923.0</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>1.224007</td>\n",
       "      <td>3.130384</td>\n",
       "      <td>0.509011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 12:00:00+00:00</td>\n",
       "      <td>2025-06-02 20:00:00+00:00</td>\n",
       "      <td>21153.0</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>1.363490</td>\n",
       "      <td>1.844227</td>\n",
       "      <td>0.507209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start_time                  end_time   n_bars  \\\n",
       "fold                                                                \n",
       "0    2023-01-03 12:00:00+00:00 2023-06-28 20:00:00+00:00   4233.0   \n",
       "1    2023-01-03 12:00:00+00:00 2023-12-22 02:00:00+00:00   8463.0   \n",
       "2    2023-01-03 12:00:00+00:00 2024-06-15 08:00:00+00:00  12693.0   \n",
       "3    2023-01-03 12:00:00+00:00 2024-12-08 14:00:00+00:00  16923.0   \n",
       "4    2023-01-03 12:00:00+00:00 2025-06-02 20:00:00+00:00  21153.0   \n",
       "\n",
       "      mean_return  volatility  annualised_vol  sharpe_ratio  hit_rate  \n",
       "fold                                                                   \n",
       "0        0.000564    0.012423        1.162749      4.248437  0.504370  \n",
       "1        0.000429    0.010998        1.029359      3.654064  0.505731  \n",
       "2        0.000501    0.012484        1.168447      3.754545  0.509415  \n",
       "3        0.000437    0.013078        1.224007      3.130384  0.509011  \n",
       "4        0.000287    0.014568        1.363490      1.844227  0.507209  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performa walk-forward (test folds):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>n_bars</th>\n",
       "      <th>mean_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>annualised_vol</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>hit_rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-06-28 21:00:00+00:00</td>\n",
       "      <td>2023-12-22 02:00:00+00:00</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.009355</td>\n",
       "      <td>0.875586</td>\n",
       "      <td>2.948867</td>\n",
       "      <td>0.507092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-22 03:00:00+00:00</td>\n",
       "      <td>2024-06-15 08:00:00+00:00</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.015021</td>\n",
       "      <td>1.405913</td>\n",
       "      <td>4.010713</td>\n",
       "      <td>0.516785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-15 09:00:00+00:00</td>\n",
       "      <td>2024-12-08 14:00:00+00:00</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.014714</td>\n",
       "      <td>1.377184</td>\n",
       "      <td>1.572112</td>\n",
       "      <td>0.507801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-12-08 15:00:00+00:00</td>\n",
       "      <td>2025-06-02 20:00:00+00:00</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>-0.000314</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>1.816330</td>\n",
       "      <td>-1.516491</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-06-02 21:00:00+00:00</td>\n",
       "      <td>2025-11-26 02:00:00+00:00</td>\n",
       "      <td>4230.0</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>1.505957</td>\n",
       "      <td>1.584231</td>\n",
       "      <td>0.516312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    start_time                  end_time  n_bars  mean_return  \\\n",
       "fold                                                                            \n",
       "0    2023-06-28 21:00:00+00:00 2023-12-22 02:00:00+00:00  4230.0     0.000295   \n",
       "1    2023-12-22 03:00:00+00:00 2024-06-15 08:00:00+00:00  4230.0     0.000644   \n",
       "2    2024-06-15 09:00:00+00:00 2024-12-08 14:00:00+00:00  4230.0     0.000247   \n",
       "3    2024-12-08 15:00:00+00:00 2025-06-02 20:00:00+00:00  4230.0    -0.000314   \n",
       "4    2025-06-02 21:00:00+00:00 2025-11-26 02:00:00+00:00  4230.0     0.000272   \n",
       "\n",
       "      volatility  annualised_vol  sharpe_ratio  hit_rate  \n",
       "fold                                                      \n",
       "0       0.009355        0.875586      2.948867  0.507092  \n",
       "1       0.015021        1.405913      4.010713  0.516785  \n",
       "2       0.014714        1.377184      1.572112  0.507801  \n",
       "3       0.019406        1.816330     -1.516491  0.500000  \n",
       "4       0.016090        1.505957      1.584231  0.516312  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_columns = [col for col in dataset.columns if col not in ['target', 'future_return']]\n",
    "\n",
    "splitter = TimeSeriesSplit(n_splits=WALKFORWARD_SPLITS)\n",
    "train_folds: list[tuple[int, pd.DataFrame]] = []\n",
    "test_folds: list[tuple[int, pd.DataFrame]] = []\n",
    "split_records: list[dict] = []\n",
    "\n",
    "for fold_id, (train_idx, test_idx) in enumerate(splitter.split(dataset)):\n",
    "    fold_train = dataset.iloc[train_idx].copy()\n",
    "    fold_test = dataset.iloc[test_idx].copy()\n",
    "    train_folds.append((fold_id, fold_train))\n",
    "    test_folds.append((fold_id, fold_test))\n",
    "    split_records.append(\n",
    "        {\n",
    "            'fold': fold_id,\n",
    "            'train_start_time': fold_train.index.min(),\n",
    "            'train_end_time': fold_train.index.max(),\n",
    "            'test_start_time': fold_test.index.min(),\n",
    "            'test_end_time': fold_test.index.max(),\n",
    "            'n_train': len(fold_train),\n",
    "            'n_test': len(fold_test),\n",
    "        }\n",
    "    )\n",
    "\n",
    "if not train_folds or not test_folds:\n",
    "    raise ValueError('TimeSeriesSplit gagal menghasilkan fold untuk dataset.')\n",
    "\n",
    "train = train_folds[-1][1]\n",
    "test = test_folds[-1][1]\n",
    "\n",
    "train_split = pd.concat({fold: frame for fold, frame in train_folds}, names=['fold', 'time'])\n",
    "test_split = pd.concat({fold: frame for fold, frame in test_folds}, names=['fold', 'time'])\n",
    "cv_split_summary = pd.DataFrame(split_records).set_index('fold')\n",
    "\n",
    "train_fold_performance = summarise_fold_performance(\n",
    "    train_folds, return_column='future_return', bars_per_year=BARS_PER_YEAR\n",
    ")\n",
    "test_fold_performance = summarise_fold_performance(\n",
    "    test_folds, return_column='future_return', bars_per_year=BARS_PER_YEAR\n",
    ")\n",
    "print('Performa walk-forward (train folds):')\n",
    "display(train_fold_performance)\n",
    "print('Performa walk-forward (test folds):')\n",
    "display(test_fold_performance)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = pd.DataFrame(\n",
    "    scaler.fit_transform(train[feature_columns]),\n",
    "    index=train.index,\n",
    "    columns=feature_columns,\n",
    ")\n",
    "X_test = pd.DataFrame(\n",
    "    scaler.transform(test[feature_columns]),\n",
    "    index=test.index,\n",
    "    columns=feature_columns,\n",
    ")\n",
    "\n",
    "def drop_low_variance_features(\n",
    "    X_tr: pd.DataFrame, X_te: pd.DataFrame, tol: float = 1e-9\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame, list[str]]:\n",
    "    variances = X_tr.var(axis=0)\n",
    "    keep_cols = variances[variances > tol].index.tolist()\n",
    "    dropped = sorted(set(X_tr.columns) - set(keep_cols))\n",
    "    if dropped:\n",
    "        print('Menghapus fitur dengan varians sangat kecil: ' + ', '.join(dropped))\n",
    "    return X_tr[keep_cols], X_te[keep_cols], keep_cols\n",
    "\n",
    "X_train, X_test, feature_columns = drop_low_variance_features(X_train, X_test)\n",
    "\n",
    "y_train = train['target']\n",
    "y_test = test['target']\n",
    "y_test_returns = test['future_return']\n",
    "\n",
    "cv_splits = min(WALKFORWARD_SPLITS, len(train) - 1)\n",
    "if cv_splits < 2:\n",
    "    raise ValueError('Dataset train terlalu pendek untuk membuat CV splits.')\n",
    "tscv = TimeSeriesSplit(n_splits=cv_splits)\n",
    "\n",
    "def get_probabilities(model, X: pd.DataFrame) -> np.ndarray:\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        return model.predict_proba(X)[:, 1]\n",
    "\n",
    "    if hasattr(model, 'decision_function'):\n",
    "        decision = model.decision_function(X)\n",
    "        return 1.0 / (1.0 + np.exp(-decision))\n",
    "\n",
    "    preds = model.predict(X)\n",
    "    return preds.astype(float)\n",
    "\n",
    "def sharpe_ratio(signal: pd.Series, realized_returns: pd.Series, periods: int = 252) -> float:\n",
    "    pnl = signal * realized_returns\n",
    "    std = pnl.std(ddof=0)\n",
    "    if std == 0 or np.isnan(std):\n",
    "        return 0.0\n",
    "    return pnl.mean() / std * np.sqrt(periods)\n",
    "\n",
    "def root_mean_squared_error(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "    \"\"\"Hitung RMSE yang kompatibel dengan berbagai versi scikit-learn.\"\"\"\n",
    "    try:\n",
    "        return float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        return float(mean_squared_error(y_true, y_pred) ** 0.5)\n",
    "\n",
    "def rolling_cv_metrics(model, X: pd.DataFrame, y: pd.Series, splitter: TimeSeriesSplit):\n",
    "    preds = pd.Series(index=y.index, dtype=float)\n",
    "    accs, aucs = [], []\n",
    "    for train_idx, val_idx in splitter.split(X):\n",
    "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        estimator = clone(model)\n",
    "        estimator.fit(X_tr, y_tr)\n",
    "        probs = get_probabilities(estimator, X_val)\n",
    "        preds.iloc[val_idx] = probs\n",
    "        accs.append(accuracy_score(y_val, (probs >= 0.5).astype(int)))\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_val, probs))\n",
    "        except ValueError:\n",
    "            aucs.append(np.nan)\n",
    "    return preds, {'cv_accuracy': float(np.nanmean(accs)), 'cv_auc': float(np.nanmean(aucs))}\n",
    "\n",
    "def fit_and_evaluate(model, X_tr, y_tr, X_te, y_te, realized_returns):\n",
    "    estimator = clone(model)\n",
    "    estimator.fit(X_tr, y_tr)\n",
    "    probs = get_probabilities(estimator, X_te)\n",
    "    predictions = (probs >= 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_te, predictions)\n",
    "    auc = roc_auc_score(y_te, probs)\n",
    "    signal = pd.Series(probs, index=y_te.index)\n",
    "    signal = 2 * signal - 1\n",
    "    sharpe = sharpe_ratio(signal, realized_returns.loc[signal.index], periods=24 * 365)\n",
    "    metrics = {\n",
    "        'accuracy': float(accuracy),\n",
    "        'roc_auc': float(auc),\n",
    "        'signal_sharpe': float(sharpe),\n",
    "    }\n",
    "    return estimator, probs, signal, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd891f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[lasso] CV metrics: {'cv_accuracy': 0.5403687943262411, 'cv_auc': 0.5534735600647074}\n",
      "[lasso] Test metrics: {'accuracy': 0.516548463356974, 'roc_auc': 0.5218614271033626, 'signal_sharpe': -0.5026925535188294}\n",
      "[elasticnet] CV metrics: {'cv_accuracy': 0.5404822695035462, 'cv_auc': 0.5535003242056233}\n",
      "[elasticnet] Test metrics: {'accuracy': 0.5177304964539007, 'roc_auc': 0.5217108160656547, 'signal_sharpe': -0.538620184693603}\n",
      "[logreg] Prediksi disimpan ke C:\\Users\\jefri\\backtest-indicator\\outputs\\predictions\\ml_logreg_baseline_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "linear_models = {\n",
    "    \"lasso\": LogisticRegression(penalty=\"l1\", solver=\"liblinear\", max_iter=5000, random_state=42),\n",
    "    \"elasticnet\": LogisticRegression(\n",
    "        penalty=\"elasticnet\",\n",
    "        solver=\"saga\",\n",
    "        l1_ratio=0.5,\n",
    "        max_iter=5000,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "linear_results = {}\n",
    "logreg_prediction_frame = pd.DataFrame()\n",
    "for name, model in linear_models.items():\n",
    "    cv_preds, cv_metrics = rolling_cv_metrics(model, X_train, y_train, tscv)\n",
    "    estimator, probs, signal, test_metrics = fit_and_evaluate(\n",
    "        model, X_train, y_train, X_test, y_test, y_test_returns\n",
    "    )\n",
    "    linear_results[name] = {\n",
    "        \"model\": estimator,\n",
    "        \"cv_metrics\": cv_metrics,\n",
    "        \"test_metrics\": test_metrics,\n",
    "        \"probabilities\": pd.Series(probs, index=X_test.index),\n",
    "        \"signals\": pd.Series(signal, index=X_test.index),\n",
    "    }\n",
    "    print(f\"[{name}] CV metrics: {cv_metrics}\")\n",
    "    print(f\"[{name}] Test metrics: {test_metrics}\")\n",
    "linear_results\n",
    "\n",
    "linear_metrics = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        name: {\n",
    "            \"cv_accuracy\": result['cv_metrics'].get('cv_accuracy'),\n",
    "            \"cv_auc\": result['cv_metrics'].get('cv_auc'),\n",
    "            \"test_accuracy\": result['test_metrics'].get('accuracy'),\n",
    "            \"test_roc_auc\": result['test_metrics'].get('roc_auc'),\n",
    "            \"test_signal_sharpe\": result['test_metrics'].get('signal_sharpe'),\n",
    "        }\n",
    "        for name, result in linear_results.items()\n",
    "    },\n",
    "    orient=\"index\",\n",
    ").rename_axis(\"model\")\n",
    "linear_metrics[\"deployment_decision\"] = np.where(\n",
    "    linear_metrics[\"test_signal_sharpe\"] > 0,\n",
    "    \"candidate\",\n",
    "    \"reject_negative_sharpe\",\n",
    ")\n",
    "linear_metrics\n",
    "\n",
    "if linear_results:\n",
    "    best_logreg = max(\n",
    "        linear_results.items(),\n",
    "        key=lambda item: item[1][\"test_metrics\"].get(\"signal_sharpe\", float('-inf')),\n",
    "    )\n",
    "    best_name, best_result = best_logreg\n",
    "    logreg_prediction_frame = pd.DataFrame(\n",
    "        {\n",
    "            \"probability\": best_result[\"probabilities\"],\n",
    "            \"signal\": 2 * best_result[\"probabilities\"] - 1,\n",
    "            \"future_return\": y_test_returns.loc[X_test.index],\n",
    "        },\n",
    "        index=X_test.index,\n",
    "    )\n",
    "    logreg_prediction_frame[\"position\"] = np.sign(logreg_prediction_frame[\"signal\"])\n",
    "    logreg_prediction_frame[\"pnl\"] = logreg_prediction_frame[\"position\"] * logreg_prediction_frame[\"future_return\"]\n",
    "    logreg_prediction_path = PREDICTION_DIR / \"ml_logreg_baseline_predictions.csv\"\n",
    "    logreg_prediction_frame.to_csv(logreg_prediction_path, index_label=\"time\")\n",
    "    print(f\"[logreg] Prediksi disimpan ke {logreg_prediction_path}\")\n",
    "else:\n",
    "    logreg_prediction_frame = pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64dd32e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[linear] MAE=0.011194, RMSE=0.016164, R2=-0.0092, Sharpe=-2.5138\n",
      "[ridge] MAE=0.011194, RMSE=0.016164, R2=-0.0092, Sharpe=-2.5487\n",
      "[lasso] MAE=0.011129, RMSE=0.016090, R2=-0.0000, Sharpe=0.0000\n",
      "[linreg] Prediksi disimpan ke C:\\Users\\jefri\\backtest-indicator\\outputs\\predictions\\ml_linreg_baseline_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "regression_models = {\n",
    "    \"linear\": LinearRegression(),\n",
    "    \"ridge\": Ridge(alpha=1.0, random_state=42),\n",
    "    \"lasso\": Lasso(alpha=1e-3, max_iter=5000, random_state=42),\n",
    "}\n",
    "\n",
    "y_train_reg = train[\"future_return\"]\n",
    "y_test_reg = y_test_returns\n",
    "\n",
    "regression_results = {}\n",
    "linreg_prediction_frame = pd.DataFrame()\n",
    "for name, model in regression_models.items():\n",
    "    estimator = clone(model)\n",
    "    estimator.fit(X_train, y_train_reg)\n",
    "    preds = pd.Series(estimator.predict(X_test), index=y_test_reg.index)\n",
    "    mae = mean_absolute_error(y_test_reg, preds)\n",
    "    rmse = root_mean_squared_error(y_test_reg, preds)\n",
    "    r2 = r2_score(y_test_reg, preds)\n",
    "    strength_bins = pd.qcut(preds.abs(), q=5, labels=False, duplicates=\"drop\")\n",
    "    max_bin = strength_bins.max()\n",
    "    strength = (strength_bins + 1) / max_bin if pd.notna(max_bin) and max_bin > 0 else strength_bins.fillna(0)\n",
    "    signal = np.sign(preds) * strength.fillna(0.0)\n",
    "    sharpe = sharpe_ratio(signal, y_test_reg, periods=int(24 * 365))\n",
    "    regression_results[name] = {\n",
    "        \"model\": estimator,\n",
    "        \"predictions\": preds,\n",
    "        \"strength\": strength,\n",
    "        \"signal\": signal,\n",
    "        \"metrics\": {\n",
    "            \"mae\": float(mae),\n",
    "            \"rmse\": float(rmse),\n",
    "            \"r2\": float(r2),\n",
    "            \"signal_sharpe\": float(sharpe),\n",
    "        },\n",
    "    }\n",
    "    print(f\"[{name}] MAE={mae:.6f}, RMSE={rmse:.6f}, R2={r2:.4f}, Sharpe={sharpe:.4f}\")\n",
    "\n",
    "regression_metrics = pd.DataFrame.from_dict(\n",
    "    {name: result[\"metrics\"] for name, result in regression_results.items()},\n",
    "    orient=\"index\",\n",
    ").rename_axis(\"model\")\n",
    "regression_metrics\n",
    "\n",
    "if regression_results:\n",
    "    best_linreg = max(\n",
    "        regression_results.items(),\n",
    "        key=lambda item: item[1][\"metrics\"].get(\"signal_sharpe\", float('-inf')),\n",
    "    )\n",
    "    best_name, best_result = best_linreg\n",
    "    linreg_prediction_frame = pd.DataFrame(\n",
    "        {\n",
    "            \"predicted_return\": best_result[\"predictions\"],\n",
    "            \"signal_strength\": best_result[\"strength\"],\n",
    "            \"signal\": best_result[\"signal\"],\n",
    "            \"future_return\": y_test_reg,\n",
    "        },\n",
    "        index=y_test_reg.index,\n",
    "    )\n",
    "    linreg_prediction_frame[\"position\"] = np.sign(linreg_prediction_frame[\"signal\"])\n",
    "    linreg_prediction_frame[\"pnl\"] = linreg_prediction_frame[\"position\"] * linreg_prediction_frame[\"future_return\"]\n",
    "    linreg_prediction_path = PREDICTION_DIR / \"ml_linreg_baseline_predictions.csv\"\n",
    "    linreg_prediction_frame.to_csv(linreg_prediction_path, index_label=\"time\")\n",
    "    print(f\"[linreg] Prediksi disimpan ke {linreg_prediction_path}\")\n",
    "else:\n",
    "    linreg_prediction_frame = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e5b0ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1780, number of negative: 1748\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 3528, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504535 -> initscore=0.018141\n",
      "[LightGBM] [Info] Start training from score 0.018141\n",
      "[LightGBM] [Info] Number of positive: 3528, number of negative: 3525\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 7053, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500213 -> initscore=0.000851\n",
      "[LightGBM] [Info] Start training from score 0.000851\n",
      "[LightGBM] [Info] Number of positive: 5390, number of negative: 5188\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 10578, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.509548 -> initscore=0.038197\n",
      "[LightGBM] [Info] Start training from score 0.038197\n",
      "[LightGBM] [Info] Number of positive: 7159, number of negative: 6944\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000562 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 14103, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507622 -> initscore=0.030492\n",
      "[LightGBM] [Info] Start training from score 0.030492\n",
      "[LightGBM] [Info] Number of positive: 8970, number of negative: 8658\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000678 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 17628, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.508850 -> initscore=0.035402\n",
      "[LightGBM] [Info] Start training from score 0.035402\n",
      "[LightGBM] [Info] Number of positive: 10729, number of negative: 10424\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 21153, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.507209 -> initscore=0.028840\n",
      "[LightGBM] [Info] Start training from score 0.028840\n",
      "[lightgbm] CV metrics: {'cv_accuracy': 0.5192624113475177, 'cv_auc': 0.530657396395004}\n",
      "[lightgbm] Test metrics: {'accuracy': 0.5278959810874705, 'roc_auc': 0.531046238707529, 'signal_sharpe': 0.7188390767974948}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cv_accuracy</th>\n",
       "      <th>cv_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_roc_auc</th>\n",
       "      <th>test_signal_sharpe</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lightgbm</th>\n",
       "      <td>0.519262</td>\n",
       "      <td>0.530657</td>\n",
       "      <td>0.527896</td>\n",
       "      <td>0.531046</td>\n",
       "      <td>0.718839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          cv_accuracy    cv_auc  test_accuracy  test_roc_auc  \\\n",
       "model                                                          \n",
       "lightgbm     0.519262  0.530657       0.527896      0.531046   \n",
       "\n",
       "          test_signal_sharpe  \n",
       "model                         \n",
       "lightgbm            0.718839  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_lgb = X_train.astype(np.float32)\n",
    "X_test_lgb = X_test.astype(np.float32)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=31,\n",
    "    max_depth=-1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_samples=5,\n",
    "    min_child_weight=1e-3,\n",
    "    feature_pre_filter=False,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "_, lgb_cv_metrics = rolling_cv_metrics(lgb_model, X_train_lgb, y_train, tscv)\n",
    "lgb_fitted, lgb_probs, lgb_signal, lgb_test_metrics = fit_and_evaluate(\n",
    "    lgb_model, X_train_lgb, y_train, X_test_lgb, y_test, y_test_returns\n",
    ")\n",
    "\n",
    "print(\"[lightgbm] CV metrics:\", lgb_cv_metrics)\n",
    "print(\"[lightgbm] Test metrics:\", lgb_test_metrics)\n",
    "\n",
    "joblib.dump(lgb_fitted, MODEL_DIR / \"lightgbm_ml_baseline.pkl\")\n",
    "lgb_prediction_frame = pd.DataFrame(\n",
    "    {\n",
    "        \"probability\": lgb_probs,\n",
    "        \"signal\": lgb_signal,\n",
    "        \"future_return\": y_test_returns.loc[X_test.index],\n",
    "    },\n",
    "    index=X_test.index,\n",
    ")\n",
    "lgb_prediction_frame[\"position\"] = np.sign(lgb_prediction_frame[\"signal\"])\n",
    "lgb_prediction_frame[\"pnl\"] = lgb_prediction_frame[\"position\"] * lgb_prediction_frame[\"future_return\"]\n",
    "lgb_prediction_path = PREDICTION_DIR / \"lightgbm_ml_baseline_predictions.csv\"\n",
    "lgb_prediction_frame.to_csv(lgb_prediction_path, index_label=\"time\")\n",
    "lgb_prediction_frame.head()\n",
    "\n",
    "try:\n",
    "    probability_bins = pd.qcut(\n",
    "        lgb_prediction_frame[\"probability\"], q=10, duplicates=\"drop\"\n",
    "    )\n",
    "except ValueError:\n",
    "    probability_bins = pd.cut(lgb_prediction_frame[\"probability\"], bins=5)\n",
    "probability_calibration = (\n",
    "    lgb_prediction_frame.assign(prob_bucket=probability_bins)\n",
    "    .groupby(\"prob_bucket\", observed=False)\n",
    "    .agg(\n",
    "        sample_size=(\"future_return\", \"size\"),\n",
    "        avg_future_return=(\"future_return\", \"mean\"),\n",
    "        avg_signal=(\"signal\", \"mean\"),\n",
    "        avg_position=(\"position\", \"mean\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "lgb_metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"cv_accuracy\": [lgb_cv_metrics.get('cv_accuracy')],\n",
    "        \"cv_auc\": [lgb_cv_metrics.get('cv_auc')],\n",
    "        \"test_accuracy\": [lgb_test_metrics.get('accuracy')],\n",
    "        \"test_roc_auc\": [lgb_test_metrics.get('roc_auc')],\n",
    "        \"test_signal_sharpe\": [lgb_test_metrics.get('signal_sharpe')],\n",
    "    },\n",
    "    index=pd.Index([\"lightgbm\"], name=\"model\"),\n",
    ")\n",
    "lgb_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96b513",
   "metadata": {},
   "source": [
    "# Evaluasi metrik regresi\n",
    "Fungsi `root_mean_squared_error` didefinisikan di sel sebelumnya untuk menjaga kompatibilitas versi scikit-learn ketika menghitung RMSE. Gunakan fungsi tersebut pada sel-sel evaluasi di bawah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67848bb7",
   "metadata": {},
   "source": [
    "(Sel ini sengaja dikosongkan; logika evaluasi regresi ada pada sel berikutnya.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19726e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[linear] MAE=0.011194, RMSE=0.016164, R2=-0.0092\n",
      "[ridge] MAE=0.011194, RMSE=0.016164, R2=-0.0092\n",
      "[lasso] MAE=0.011129, RMSE=0.016090, R2=-0.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>linear</th>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>-9.188266e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ridge</th>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>-9.198508e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lasso</th>\n",
       "      <td>0.011129</td>\n",
       "      <td>0.016090</td>\n",
       "      <td>-8.350624e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mae      rmse            r2\n",
       "model                                   \n",
       "linear  0.011194  0.016164 -9.188266e-03\n",
       "ridge   0.011194  0.016164 -9.198508e-03\n",
       "lasso   0.011129  0.016090 -8.350624e-07"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_reg = train['future_return']\n",
    "y_test_reg = y_test_returns\n",
    "\n",
    "regression_models = {\n",
    "    'linear': LinearRegression(),\n",
    "    'ridge': Ridge(alpha=1.0, random_state=42),\n",
    "    'lasso': Lasso(alpha=1e-3, max_iter=5000, random_state=42),\n",
    "}\n",
    "\n",
    "regression_rows = []\n",
    "for name, model in regression_models.items():\n",
    "    estimator = clone(model)\n",
    "    estimator.fit(X_train, y_train_reg)\n",
    "    preds = estimator.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test_reg, preds)\n",
    "    rmse = root_mean_squared_error(y_test_reg, preds)\n",
    "    r2 = r2_score(y_test_reg, preds)\n",
    "    regression_rows.append(\n",
    "        {\n",
    "            'model': name,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse,\n",
    "            'r2': r2,\n",
    "        }\n",
    "    )\n",
    "    print(f\"[{name}] MAE={mae:.6f}, RMSE={rmse:.6f}, R2={r2:.4f}\")\n",
    "\n",
    "regression_model_metrics = pd.DataFrame(regression_rows).set_index('model')\n",
    "regression_model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fcde33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mae</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lightgbm_signal</th>\n",
       "      <td>0.177815</td>\n",
       "      <td>0.229775</td>\n",
       "      <td>-202.930659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mae      rmse          r2\n",
       "model                                          \n",
       "lightgbm_signal  0.177815  0.229775 -202.930659"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluasi metrik regresi untuk sinyal probabilitas LightGBM\n",
    "y_test_reg = y_test_returns.loc[lgb_prediction_frame.index]\n",
    "regression_preds = lgb_prediction_frame['signal']\n",
    "\n",
    "mae = mean_absolute_error(y_test_reg, regression_preds)\n",
    "rmse = root_mean_squared_error(y_test_reg, regression_preds)\n",
    "r2 = r2_score(y_test_reg, regression_preds)\n",
    "\n",
    "signal_regression_metrics = pd.DataFrame(\n",
    "    {\n",
    "        'mae': [mae],\n",
    "        'rmse': [rmse],\n",
    "        'r2': [r2],\n",
    "    },\n",
    "    index=pd.Index(['lightgbm_signal'], name='model'),\n",
    ")\n",
    "signal_regression_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34438b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Berhasil mengekspor 15 sheet ke C:\\Users\\jefri\\backtest-indicator\\outputs\\result-test\\ml_baseline.xlsx (engine: openpyxl)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Users/jefri/backtest-indicator/outputs/result-test/ml_baseline.xlsx')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import importlib.util\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "try:\n",
    "    PROJECT_ROOT\n",
    "except NameError:  # pragma: no cover - notebook convenience\n",
    "    PROJECT_ROOT = Path.cwd()\n",
    "\n",
    "\n",
    "def export_tables_to_excel(tables, path: Path) -> Path:\n",
    "    def strip_timezone_from_value(value):\n",
    "        if value is pd.NaT:\n",
    "            return value\n",
    "        if isinstance(value, pd.Timestamp):\n",
    "            if value.tz is not None:\n",
    "                return value.tz_convert('UTC').tz_localize(None)\n",
    "            return value\n",
    "        if isinstance(value, datetime):\n",
    "            if value.tzinfo is not None:\n",
    "                return value.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "            return value\n",
    "        return value\n",
    "\n",
    "    def strip_timezone_from_axis(axis):\n",
    "        if isinstance(axis, pd.MultiIndex):\n",
    "            new_levels = [strip_timezone_from_axis(level) for level in axis.levels]\n",
    "            return axis.set_levels(new_levels)\n",
    "        if isinstance(axis, pd.DatetimeIndex) and axis.tz is not None:\n",
    "            return axis.tz_convert('UTC').tz_localize(None)\n",
    "        if getattr(axis, 'dtype', None) == object:\n",
    "            return pd.Index([strip_timezone_from_value(val) for val in axis], name=axis.name)\n",
    "        return axis\n",
    "\n",
    "    def make_excel_safe(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "        frame = frame.copy()\n",
    "        frame.index = strip_timezone_from_axis(frame.index)\n",
    "        frame.columns = strip_timezone_from_axis(frame.columns)\n",
    "        for column in frame.columns:\n",
    "            series = frame[column]\n",
    "            if isinstance(series.dtype, pd.DatetimeTZDtype):\n",
    "                frame[column] = series.dt.tz_convert('UTC').dt.tz_localize(None)\n",
    "            elif series.dtype == object:\n",
    "                frame[column] = series.map(strip_timezone_from_value)\n",
    "        return frame\n",
    "\n",
    "    serialisable = []\n",
    "    for sheet_name, table in tables.items():\n",
    "        if table is None:\n",
    "            continue\n",
    "        if isinstance(table, pd.Series):\n",
    "            frame = table.to_frame()\n",
    "        elif isinstance(table, pd.DataFrame):\n",
    "            frame = table.copy()\n",
    "        elif isinstance(table, dict):\n",
    "            frame = pd.DataFrame([table])\n",
    "        else:\n",
    "            frame = pd.DataFrame(table)\n",
    "        frame = make_excel_safe(frame)\n",
    "        serialisable.append((sheet_name, frame))\n",
    "\n",
    "    if not serialisable:\n",
    "        raise ValueError('Tidak ada tabel yang bisa diekspor.')\n",
    "\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    def pick_engine() -> str:\n",
    "        for candidate in ('openpyxl', 'xlsxwriter'):\n",
    "            if importlib.util.find_spec(candidate):\n",
    "                return candidate\n",
    "        raise ModuleNotFoundError(\n",
    "            \"Untuk ekspor Excel diperlukan paket 'openpyxl' atau 'xlsxwriter'.\"\n",
    "        )\n",
    "\n",
    "    def normalise_sheet_name(name: str, existing) -> str:\n",
    "        safe = (name or 'Sheet').strip() or 'Sheet'\n",
    "        safe = safe[:31]\n",
    "        counter = 1\n",
    "        candidate = safe\n",
    "        while candidate in existing:\n",
    "            suffix = f'_{counter}'\n",
    "            trimmed = safe[: 31 - len(suffix)] or 'Sheet'\n",
    "            candidate = f\"{trimmed}{suffix}\"\n",
    "            counter += 1\n",
    "        existing.add(candidate)\n",
    "        return candidate\n",
    "\n",
    "    engine = pick_engine()\n",
    "    used_names = set()\n",
    "    with pd.ExcelWriter(path, engine=engine) as writer:\n",
    "        for sheet_name, frame in serialisable:\n",
    "            name = normalise_sheet_name(str(sheet_name), used_names)\n",
    "            frame.to_excel(writer, sheet_name=name, index=True)\n",
    "    print(\n",
    "        f\"Berhasil mengekspor {len(serialisable)} sheet ke {path} (engine: {engine})\"\n",
    "    )\n",
    "    return path\n",
    "\n",
    "\n",
    "export_dir = PROJECT_ROOT / 'outputs' / 'result-test'\n",
    "export_path = export_dir / 'ml_baseline.xlsx'\n",
    "export_tables_to_excel(\n",
    "    {\n",
    "        'dataset': dataset,\n",
    "        'dataset_metadata': dataset_metadata,\n",
    "        'train_split': train_split,\n",
    "        'test_split': test_split,\n",
    "        'cv_split_summary': cv_split_summary,\n",
    "        'train_fold_performance': train_fold_performance,\n",
    "        'test_fold_performance': test_fold_performance,\n",
    "        'final_train_window': train,\n",
    "        'final_test_window': test,\n",
    "        'linear_model_metrics': linear_metrics,\n",
    "        'lightgbm_metrics': lgb_metrics,\n",
    "        'probability_calibration': probability_calibration,\n",
    "        'predictions': lgb_prediction_frame,\n",
    "        'signal_regression_metrics': signal_regression_metrics,\n",
    "        'regression_model_metrics': regression_model_metrics,\n",
    "    },\n",
    "    export_path,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
